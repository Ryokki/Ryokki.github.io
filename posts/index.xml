<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ryokki Site</title>
    <link>https://ryokki.github.io/posts/</link>
    <description>Recent content in Posts on Ryokki Site</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>This is a customized copyright.</copyright>
    <lastBuildDate>Wed, 19 Feb 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://ryokki.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>内存屏障的前世今生</title>
      <link>https://ryokki.github.io/posts/021.-%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/</link>
      <pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://ryokki.github.io/posts/021.-%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/</guid>
      <description>参考 Locks实现:背后不为人知的故事 - MySpace&#xA;以及下面两个视频很清楚解释了cpu cache,MESI, store buffer/invalidation queue, 内存屏障的历史演进&#xA;【面试官问我MESI如何保证内存一致性，我把这个动画甩给他】 https://www.bilibili.com/video/BV1kD4y1T7XU/?share_source=copy_web&amp;amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 【美团一面问我内存屏障和volatile的关系，我说了20分钟】 https://www.bilibili.com/video/BV1cT411a7Sn/?share_source=copy_web&amp;amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 多个CPU或CPU Core之间通过总线连接； CPU通过总线与主存（memory）连接； 每个CPU都有自己的本地cache，通过cache一致性协议（如MESI/MESIF）与其他CPU Core维护一个一致的数据视图； 引入store buffer CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销（执行cache一致性协议），CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。&#xA;数据更新不直接写cacheline而是先写到store buffer，后面需要时再落cache并通知其他cache失效（执行cache一致性协议），这样CPU就可以减少stall继续执行指令（store buffer刷新过程不需要cpu参与）。&#xA;💡单核时保证了一致性&#xA;store buffer是个FIFO，同个cpu两个写操作一定是顺序执行的 同个cpu先写后读，不会出现读到旧数据的情况，因为读的时候会检查store buffer是否有同个地址的写操作 引入invalidate queue CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI/MESIF消息invalidate。&#xA;正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。&#xA;（invalidate queue 刷新过程不需要cpu参与）&#xA;引入的问题 这么设计引入的问题：&#xA;store buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见； invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据（其实就是第一点，写操作对外不可见） 处理器执行操作变化 如果没有store buffer、invalidate queue，MESI，cache如何工作？&#xA;当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate； 当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据； CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。 如果引入了store buffer、invalidate queue之后，又该如何工作呢？&#xA;必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate； 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据； 内存屏障 这里的读写屏障要依赖处理器提供的屏障指令 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 lock; addl来实现读写屏障 smp_mb/smp_rmb/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令 lock;addl同时实现全屏障/读屏障/写屏障足矣。 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了 写操作后加入写屏障，就会刷新该cpu的所有store buffer，刷到其他cpu的invaliate queue 读操作前加入读屏障，就会消费当前cpu的所有invalidate DeepSeek-R1对演进史的梳理 帮我这个笔记做下补充，例如展开说说演进的历史（结合时间），更具体的例子等等 cpu-memory很慢，引入cache 由于每个cpu都有各自的cache，修改时需要保证其他缓存失效，收到ack后才能继续修改 引入两个队列 Store Buffer：用于提升写操作的性能。更新内存时，直接扔到buffer中，异步更新。buffer执行更新时，也一样是收到其他cpu的缓存失效ack后才能修改【简而言之，Store Buffer 就像一个 “写操作缓冲区”，让 CPU 可以 “先写先走”，从而避免写操作成为性能瓶颈。】 Invalid Queue: Invalidation Queue 的作用就是异步地接收和处理这些来自其他 CPU Core 的 Invalidate Request。 当 CPU Core (例如 CPU1) 收到来自 CPU0 的 Invalidate Request 时，它不会立即暂停当前正在执行的任务，去同步处理缓存失效。 相反，它会将收到的 Invalidate Request 先放入 Invalidation Queue 中排队。 CPU Core 可以继续执行后续的指令，而 Invalidation Queue 会在 后台异步地 从队列中取出 Invalidate Request，并执行相应的缓存失效操作 (例如，标记 Cache Line 为 Invalid)。【简而言之，Invalidation Queue 就像一个 “失效请求缓冲区”，让 CPU 可以异步地处理来自其他 Core 的失效请求，避免因等待失效处理而阻塞 CPU 的正常执行。】 最后的总结很好：cache-&amp;gt;mesi-&amp;gt;two queue-&amp;gt;barrier的演进 好的！我将结合时间线、具体案例和技术细节，补充并扩展您的笔记内容：</description>
    </item>
  </channel>
</rss>
