<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.129.0">

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="Kaijian Xu" />
  <meta property="og:url" content="https://ryokki.github.io/posts/021.-%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/" />
  <link rel="canonical" href="https://ryokki.github.io/posts/021.-%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/" /><link rel="alternate" type="application/atom+xml" href="https://ryokki.github.io/index.xml" title="XKJ Blog">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/ryokki.github.io\/"
      },
      "articleSection" : "posts",
      "name" : "内存屏障的前世今生",
      "headline" : "内存屏障的前世今生",
      "description" : "参考 Locks实现:背后不为人知的故事 - MySpace\n以及下面两个视频很清楚解释了cpu cache,MESI, store buffer\/invalidation queue, 内存屏障的历史演进\n【面试官问我MESI如何保证内存一致性，我把这个动画甩给他】 https:\/\/www.bilibili.com\/video\/BV1kD4y1T7XU\/?share_source=copy_web\u0026amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 【美团一面问我内存屏障和volatile的关系，我说了20分钟】 https:\/\/www.bilibili.com\/video\/BV1cT411a7Sn\/?share_source=copy_web\u0026amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 多个CPU或CPU Core之间通过总线连接； CPU通过总线与主存（memory）连接； 每个CPU都有自己的本地cache，通过cache一致性协议（如MESI\/MESIF）与其他CPU Core维护一个一致的数据视图； 引入store buffer CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销（执行cache一致性协议），CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。\n数据更新不直接写cacheline而是先写到store buffer，后面需要时再落cache并通知其他cache失效（执行cache一致性协议），这样CPU就可以减少stall继续执行指令（store buffer刷新过程不需要cpu参与）。\n💡单核时保证了一致性\nstore buffer是个FIFO，同个cpu两个写操作一定是顺序执行的 同个cpu先写后读，不会出现读到旧数据的情况，因为读的时候会检查store buffer是否有同个地址的写操作 引入invalidate queue CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI\/MESIF消息invalidate。\n正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。\n（invalidate queue 刷新过程不需要cpu参与）\n引入的问题 这么设计引入的问题：\nstore buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见； invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据（其实就是第一点，写操作对外不可见） 处理器执行操作变化 如果没有store buffer、invalidate queue，MESI，cache如何工作？\n当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate； 当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据； CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。 如果引入了store buffer、invalidate queue之后，又该如何工作呢？\n必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate； 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据； 内存屏障 这里的读写屏障要依赖处理器提供的屏障指令 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 lock; addl来实现读写屏障 smp_mb\/smp_rmb\/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令 lock;addl同时实现全屏障\/读屏障\/写屏障足矣。 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了 写操作后加入写屏障，就会刷新该cpu的所有store buffer，刷到其他cpu的invaliate queue 读操作前加入读屏障，就会消费当前cpu的所有invalidate DeepSeek-R1对演进史的梳理 帮我这个笔记做下补充，例如展开说说演进的历史（结合时间），更具体的例子等等 cpu-memory很慢，引入cache 由于每个cpu都有各自的cache，修改时需要保证其他缓存失效，收到ack后才能继续修改 引入两个队列 Store Buffer：用于提升写操作的性能。更新内存时，直接扔到buffer中，异步更新。buffer执行更新时，也一样是收到其他cpu的缓存失效ack后才能修改【简而言之，Store Buffer 就像一个 “写操作缓冲区”，让 CPU 可以 “先写先走”，从而避免写操作成为性能瓶颈。】 Invalid Queue: Invalidation Queue 的作用就是异步地接收和处理这些来自其他 CPU Core 的 Invalidate Request。 当 CPU Core (例如 CPU1) 收到来自 CPU0 的 Invalidate Request 时，它不会立即暂停当前正在执行的任务，去同步处理缓存失效。 相反，它会将收到的 Invalidate Request 先放入 Invalidation Queue 中排队。 CPU Core 可以继续执行后续的指令，而 Invalidation Queue 会在 后台异步地 从队列中取出 Invalidate Request，并执行相应的缓存失效操作 (例如，标记 Cache Line 为 Invalid)。【简而言之，Invalidation Queue 就像一个 “失效请求缓冲区”，让 CPU 可以异步地处理来自其他 Core 的失效请求，避免因等待失效处理而阻塞 CPU 的正常执行。】 最后的总结很好：cache-\u0026gt;mesi-\u0026gt;two queue-\u0026gt;barrier的演进 好的！我将结合时间线、具体案例和技术细节，补充并扩展您的笔记内容：",
      "inLanguage" : "en-US",
      "author" : "Kaijian Xu",
      "creator" : "Kaijian Xu",
      "publisher": "Kaijian Xu",
      "accountablePerson" : "Kaijian Xu",
      "copyrightHolder" : "Kaijian Xu",
      "copyrightYear" : "2025",
      "datePublished": "2025-02-19 00:00:00 \u002b0000 UTC",
      "dateModified" : "2025-02-19 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/ryokki.github.io\/posts\/021.-%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F\/",
      "keywords" : [  ]
  }
</script>
<title>内存屏障的前世今生</title>
  <meta property="og:title" content="内存屏障的前世今生" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="参考 Locks实现:背后不为人知的故事 - MySpace
以及下面两个视频很清楚解释了cpu cache,MESI, store buffer/invalidation queue, 内存屏障的历史演进
【面试官问我MESI如何保证内存一致性，我把这个动画甩给他】 https://www.bilibili.com/video/BV1kD4y1T7XU/?share_source=copy_web&amp;amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 【美团一面问我内存屏障和volatile的关系，我说了20分钟】 https://www.bilibili.com/video/BV1cT411a7Sn/?share_source=copy_web&amp;amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 多个CPU或CPU Core之间通过总线连接； CPU通过总线与主存（memory）连接； 每个CPU都有自己的本地cache，通过cache一致性协议（如MESI/MESIF）与其他CPU Core维护一个一致的数据视图； 引入store buffer CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销（执行cache一致性协议），CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。
数据更新不直接写cacheline而是先写到store buffer，后面需要时再落cache并通知其他cache失效（执行cache一致性协议），这样CPU就可以减少stall继续执行指令（store buffer刷新过程不需要cpu参与）。
💡单核时保证了一致性
store buffer是个FIFO，同个cpu两个写操作一定是顺序执行的 同个cpu先写后读，不会出现读到旧数据的情况，因为读的时候会检查store buffer是否有同个地址的写操作 引入invalidate queue CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI/MESIF消息invalidate。
正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。
（invalidate queue 刷新过程不需要cpu参与）
引入的问题 这么设计引入的问题：
store buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见； invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据（其实就是第一点，写操作对外不可见） 处理器执行操作变化 如果没有store buffer、invalidate queue，MESI，cache如何工作？
当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate； 当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据； CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。 如果引入了store buffer、invalidate queue之后，又该如何工作呢？
必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate； 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据； 内存屏障 这里的读写屏障要依赖处理器提供的屏障指令 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 lock; addl来实现读写屏障 smp_mb/smp_rmb/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令 lock;addl同时实现全屏障/读屏障/写屏障足矣。 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了 写操作后加入写屏障，就会刷新该cpu的所有store buffer，刷到其他cpu的invaliate queue 读操作前加入读屏障，就会消费当前cpu的所有invalidate DeepSeek-R1对演进史的梳理 帮我这个笔记做下补充，例如展开说说演进的历史（结合时间），更具体的例子等等 cpu-memory很慢，引入cache 由于每个cpu都有各自的cache，修改时需要保证其他缓存失效，收到ack后才能继续修改 引入两个队列 Store Buffer：用于提升写操作的性能。更新内存时，直接扔到buffer中，异步更新。buffer执行更新时，也一样是收到其他cpu的缓存失效ack后才能修改【简而言之，Store Buffer 就像一个 “写操作缓冲区”，让 CPU 可以 “先写先走”，从而避免写操作成为性能瓶颈。】 Invalid Queue: Invalidation Queue 的作用就是异步地接收和处理这些来自其他 CPU Core 的 Invalidate Request。 当 CPU Core (例如 CPU1) 收到来自 CPU0 的 Invalidate Request 时，它不会立即暂停当前正在执行的任务，去同步处理缓存失效。 相反，它会将收到的 Invalidate Request 先放入 Invalidation Queue 中排队。 CPU Core 可以继续执行后续的指令，而 Invalidation Queue 会在 后台异步地 从队列中取出 Invalidate Request，并执行相应的缓存失效操作 (例如，标记 Cache Line 为 Invalid)。【简而言之，Invalidation Queue 就像一个 “失效请求缓冲区”，让 CPU 可以异步地处理来自其他 Core 的失效请求，避免因等待失效处理而阻塞 CPU 的正常执行。】 最后的总结很好：cache-&amp;gt;mesi-&amp;gt;two queue-&amp;gt;barrier的演进 好的！我将结合时间线、具体案例和技术细节，补充并扩展您的笔记内容：" />
  <meta name="description" content="参考 Locks实现:背后不为人知的故事 - MySpace
以及下面两个视频很清楚解释了cpu cache,MESI, store buffer/invalidation queue, 内存屏障的历史演进
【面试官问我MESI如何保证内存一致性，我把这个动画甩给他】 https://www.bilibili.com/video/BV1kD4y1T7XU/?share_source=copy_web&amp;amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 【美团一面问我内存屏障和volatile的关系，我说了20分钟】 https://www.bilibili.com/video/BV1cT411a7Sn/?share_source=copy_web&amp;amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de 多个CPU或CPU Core之间通过总线连接； CPU通过总线与主存（memory）连接； 每个CPU都有自己的本地cache，通过cache一致性协议（如MESI/MESIF）与其他CPU Core维护一个一致的数据视图； 引入store buffer CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销（执行cache一致性协议），CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。
数据更新不直接写cacheline而是先写到store buffer，后面需要时再落cache并通知其他cache失效（执行cache一致性协议），这样CPU就可以减少stall继续执行指令（store buffer刷新过程不需要cpu参与）。
💡单核时保证了一致性
store buffer是个FIFO，同个cpu两个写操作一定是顺序执行的 同个cpu先写后读，不会出现读到旧数据的情况，因为读的时候会检查store buffer是否有同个地址的写操作 引入invalidate queue CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI/MESIF消息invalidate。
正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。
（invalidate queue 刷新过程不需要cpu参与）
引入的问题 这么设计引入的问题：
store buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见； invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据（其实就是第一点，写操作对外不可见） 处理器执行操作变化 如果没有store buffer、invalidate queue，MESI，cache如何工作？
当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate； 当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据； CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。 如果引入了store buffer、invalidate queue之后，又该如何工作呢？
必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate； 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据； 内存屏障 这里的读写屏障要依赖处理器提供的屏障指令 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 lock; addl来实现读写屏障 smp_mb/smp_rmb/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令 lock;addl同时实现全屏障/读屏障/写屏障足矣。 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了 写操作后加入写屏障，就会刷新该cpu的所有store buffer，刷到其他cpu的invaliate queue 读操作前加入读屏障，就会消费当前cpu的所有invalidate DeepSeek-R1对演进史的梳理 帮我这个笔记做下补充，例如展开说说演进的历史（结合时间），更具体的例子等等 cpu-memory很慢，引入cache 由于每个cpu都有各自的cache，修改时需要保证其他缓存失效，收到ack后才能继续修改 引入两个队列 Store Buffer：用于提升写操作的性能。更新内存时，直接扔到buffer中，异步更新。buffer执行更新时，也一样是收到其他cpu的缓存失效ack后才能修改【简而言之，Store Buffer 就像一个 “写操作缓冲区”，让 CPU 可以 “先写先走”，从而避免写操作成为性能瓶颈。】 Invalid Queue: Invalidation Queue 的作用就是异步地接收和处理这些来自其他 CPU Core 的 Invalidate Request。 当 CPU Core (例如 CPU1) 收到来自 CPU0 的 Invalidate Request 时，它不会立即暂停当前正在执行的任务，去同步处理缓存失效。 相反，它会将收到的 Invalidate Request 先放入 Invalidation Queue 中排队。 CPU Core 可以继续执行后续的指令，而 Invalidation Queue 会在 后台异步地 从队列中取出 Invalidate Request，并执行相应的缓存失效操作 (例如，标记 Cache Line 为 Invalid)。【简而言之，Invalidation Queue 就像一个 “失效请求缓冲区”，让 CPU 可以异步地处理来自其他 Core 的失效请求，避免因等待失效处理而阻塞 CPU 的正常执行。】 最后的总结很好：cache-&amp;gt;mesi-&amp;gt;two queue-&amp;gt;barrier的演进 好的！我将结合时间线、具体案例和技术细节，补充并扩展您的笔记内容：" />
  <meta property="og:locale" content="zh" /><meta property="og:image" content="" />
  

  
    <style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="XKJ Blog">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  
</head>


<body>
  <article class="post " id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >Kaijian Xu</a
    >
  </div>
  <div class="header-subtitle"></div>
</header>
<div class="row end-md center-xs header-items">
  
</div>
<div class="row end-xs">
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">内存屏障的前世今生</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2025-02-19 00:00:00 UTC">
                19 Feb 2025
              </time>
              
            </div>
            <div class="col-xs-6">
              
              <div class="post-author">
                <a target="_blank" href="">@Kaijian Xu</a>
              </div>
              
            </div>
          </div>
          
        </header>

        <div class="post-content markdown-body">
          
          <p>参考 <a href="https://www.hitzhangjie.pro/blog/2021-04-17-locks%E5%AE%9E%E7%8E%B0%E9%82%A3%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%95%85%E4%BA%8B/">Locks实现:背后不为人知的故事 - MySpace</a></p>
<p>以及下面两个视频很清楚解释了cpu cache,MESI, store buffer/invalidation queue, 内存屏障的历史演进</p>
<ul>
<li>【面试官问我MESI如何保证内存一致性，我把这个动画甩给他】 <a href="https://www.bilibili.com/video/BV1kD4y1T7XU/?share_source=copy_web&amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de">https://www.bilibili.com/video/BV1kD4y1T7XU/?share_source=copy_web&amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de</a></li>
<li>【美团一面问我内存屏障和volatile的关系，我说了20分钟】 <a href="https://www.bilibili.com/video/BV1cT411a7Sn/?share_source=copy_web&amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de">https://www.bilibili.com/video/BV1cT411a7Sn/?share_source=copy_web&amp;vd_source=6d5bbefdbb303f5c1b77aaeaa935d3de</a></li>
</ul>
<p><img src="https://kkbabe-picgo.oss-cn-hangzhou.aliyuncs.com/img/20250219215829.png" alt="image.png"></p>
<ul>
<li>多个CPU或CPU Core之间通过总线连接；</li>
<li>CPU通过总线与主存（memory）连接；</li>
<li>每个CPU都有自己的本地cache，通过cache一致性协议（如MESI/MESIF）与其他CPU Core维护一个一致的数据视图；</li>
</ul>
<h3 id="引入store-buffer">引入store buffer</h3>
<p>CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销（执行cache一致性协议），CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。</p>
<p>数据更新不直接写cacheline而是先写到store buffer，后面需要时再<strong>落cache</strong>并<strong>通知其他cache失效</strong>（执行cache一致性协议），这样CPU就可以减少stall继续执行指令（store buffer刷新过程不需要cpu参与）。</p>
<p><img src="https://kkbabe-picgo.oss-cn-hangzhou.aliyuncs.com/img/cpu2.png" alt="cpu2"></p>
<p>💡单核时保证了一致性</p>
<ol>
<li>store buffer是个FIFO，同个cpu两个写操作一定是顺序执行的</li>
<li>同个cpu先写后读，不会出现读到旧数据的情况，因为读的时候会检查store buffer是否有同个地址的写操作</li>
</ol>
<h3 id="引入invalidate-queue">引入invalidate queue</h3>
<p>CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI/MESIF消息invalidate。</p>
<p>正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。</p>
<p>（invalidate queue 刷新过程不需要cpu参与）</p>
<h3 id="引入的问题">引入的问题</h3>
<p>这么设计引入的问题：</p>
<ul>
<li>store buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见；</li>
<li>invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据（其实就是第一点，写操作对外不可见）</li>
</ul>
<h3 id="处理器执行操作变化">处理器执行操作变化</h3>
<p><strong>如果没有store buffer、invalidate queue，MESI，cache如何工作？</strong></p>
<ul>
<li>当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate；</li>
<li>当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据；</li>
<li>CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。</li>
</ul>
<p><strong>如果引入了store buffer、invalidate queue之后，又该如何工作呢？</strong></p>
<ul>
<li>必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate；</li>
<li>必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据；</li>
</ul>
<h3 id="内存屏障">内存屏障</h3>
<ul>
<li>这里的读写屏障要依赖处理器提供的屏障指令</li>
<li>在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 <code>lock; addl</code>来实现读写屏障 smp_mb/smp_rmb/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令 <code>lock;addl</code>同时实现全屏障/读屏障/写屏障足矣。</li>
<li>其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了</li>
</ul>
<p><img src="https://kkbabe-picgo.oss-cn-hangzhou.aliyuncs.com/img/image-20250219224237737.png" alt="image-20250219224237737"></p>
<ol>
<li>写操作后加入写屏障，就会刷新该cpu的所有store buffer，刷到其他cpu的invaliate queue</li>
<li>读操作前加入读屏障，就会消费当前cpu的所有invalidate</li>
</ol>
<h2 id="deepseek-r1对演进史的梳理">DeepSeek-R1对演进史的梳理</h2>
<pre tabindex="0"><code>帮我这个笔记做下补充，例如展开说说演进的历史（结合时间），更具体的例子等等

cpu-memory很慢，引入cache
由于每个cpu都有各自的cache，修改时需要保证其他缓存失效，收到ack后才能继续修改
引入两个队列
Store Buffer：用于提升写操作的性能。更新内存时，直接扔到buffer中，异步更新。buffer执行更新时，也一样是收到其他cpu的缓存失效ack后才能修改【简而言之，Store Buffer 就像一个 “写操作缓冲区”，让 CPU 可以 “先写先走”，从而避免写操作成为性能瓶颈。】
Invalid Queue: Invalidation Queue 的作用就是异步地接收和处理这些来自其他 CPU Core 的 Invalidate Request。 当 CPU Core (例如 CPU1) 收到来自 CPU0 的 Invalidate Request 时，它不会立即暂停当前正在执行的任务，去同步处理缓存失效。 相反，它会将收到的 Invalidate Request 先放入 Invalidation Queue 中排队。 CPU Core 可以继续执行后续的指令，而 Invalidation Queue 会在 后台异步地 从队列中取出 Invalidate Request，并执行相应的缓存失效操作 (例如，标记 Cache Line 为 Invalid)。【简而言之，Invalidation Queue 就像一个 “失效请求缓冲区”，让 CPU 可以异步地处理来自其他 Core 的失效请求，避免因等待失效处理而阻塞 CPU 的正常执行。】


最后的总结很好：cache-&gt;mesi-&gt;two queue-&gt;barrier的演进
</code></pre><p>好的！我将结合时间线、具体案例和技术细节，补充并扩展您的笔记内容：</p>
<hr>
<h3 id="cpu-cache-与内存一致性演进史"><strong>CPU Cache 与内存一致性演进史</strong></h3>
<h4 id="1-单核时代简单缓存1980s前"><strong>1. 单核时代：简单缓存（1980s前）</strong></h4>
<ul>
<li><strong>背景</strong>：CPU 主频快速提升（MHz → GHz），但内存速度仅增长 10 倍，形成 &ldquo;Memory Wall&rdquo;（内存墙）。</li>
<li><strong>早期方案</strong>：
<ul>
<li><strong>直写（Write-Through）</strong>：每次写操作同时更新缓存和内存，简单但性能差。</li>
<li><strong>回写（Write-Back）</strong>：仅更新缓存，标记脏位（Dirty Bit），淘汰时写回内存，提升性能。</li>
</ul>
</li>
<li><strong>案例</strong>：Intel 80386（1985）首次引入片上缓存（8KB），采用简单回写策略。</li>
</ul>
<hr>
<h4 id="2-多核时代mesi-协议1990s"><strong>2. 多核时代：MESI 协议（1990s）</strong></h4>
<ul>
<li><strong>问题</strong>：多核 CPU 各自缓存同一内存地址时，如何保证一致性？</li>
<li><strong>MESI 协议</strong>（1990 年提出）：
<ul>
<li><strong>状态机</strong>：Modified（独占修改）、Exclusive（独占未修改）、Shared（共享）、Invalid（失效）。</li>
<li><strong>总线嗅探（Bus Snooping）</strong>：通过监听总线消息（如 <code>Read</code>/<code>Invalidate</code>）维护状态。</li>
<li><strong>性能瓶颈</strong>：每次写操作需广播失效请求，等待所有 CPU 确认（ACK），导致延迟。</li>
</ul>
</li>
<li><strong>案例</strong>：
<ul>
<li><strong>Intel Pentium Pro（1995）</strong>：首次实现 MESI，支持多核共享 L2 缓存。</li>
<li><strong>AMD K6（1997）</strong>：采用 MOESI 协议（增加 Owned 状态），优化共享数据场景。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-异步优化store-buffer-与-invalidation-queue2000s"><strong>3. 异步优化：Store Buffer 与 Invalidation Queue（2000s）</strong></h4>
<h5 id="31-store-buffer"><strong>3.1 Store Buffer</strong></h5>
<ul>
<li><strong>问题</strong>：MESI 要求写操作必须等待所有 ACK，导致 CPU 停顿（Stall）。</li>
<li><strong>解决方案</strong>：引入 Store Buffer（写缓冲区）。
<ul>
<li><strong>工作流程</strong>：
<ol>
<li>CPU 写入时，数据暂存到 Store Buffer，继续执行后续指令。</li>
<li>后台异步发送 <code>Invalidate</code> 请求，等待其他 CPU 的 ACK。</li>
<li>收到所有 ACK 后，数据从 Store Buffer 提交到缓存（Cache Line）。</li>
</ol>
</li>
<li><strong>优化效果</strong>：写操作延迟从 100+ 周期降低到 10 周期内。</li>
<li><strong>副作用</strong>：导致<strong>内存乱序</strong>（Memory Reordering），需内存屏障（Memory Barrier）控制。</li>
</ul>
</li>
<li><strong>案例</strong>：
<ul>
<li><strong>Intel NetBurst（2000）</strong>：首次引入深度 Store Buffer（20+ entries），提升 Pentium 4 吞吐量。</li>
<li><strong>ARMv7（2005）</strong>：允许弱一致性模型（Weak Memory Model），依赖显式屏障指令。</li>
</ul>
</li>
</ul>
<h5 id="32-invalidation-queue"><strong>3.2 Invalidation Queue</strong></h5>
<ul>
<li><strong>问题</strong>：接收 <code>Invalidate</code> 请求的 CPU 若同步处理，可能因繁忙延迟 ACK。</li>
<li><strong>解决方案</strong>：引入 Invalidation Queue（失效队列）。
<ul>
<li><strong>工作流程</strong>：
<ol>
<li>收到 <code>Invalidate</code> 请求时，直接放入队列并立即回复 ACK。</li>
<li>后台异步处理队列，将对应 Cache Line 标记为 Invalid。</li>
</ol>
</li>
<li><strong>优化效果</strong>：减少 ACK 延迟，提升整体吞吐量。</li>
<li><strong>副作用</strong>：可能导致 CPU 短暂读到旧数据（需屏障强制清空队列）。</li>
</ul>
</li>
<li><strong>案例</strong>：
<ul>
<li><strong>IBM POWER4（2001）</strong>：首次实现多级 Invalidation Queue，支持 64 核系统。</li>
<li><strong>AMD Zen（2017）</strong>：采用分布式失效队列，优化多 CCD 架构延迟。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="4-内存屏障memory-barrier-2000"><strong>4. 内存屏障（Memory Barrier） (2000)</strong></h4>
<ul>
<li><strong>问题</strong>：Store Buffer 和 Invalidation Queue 导致指令重排，破坏程序顺序一致性。</li>
<li><strong>解决方案</strong>：插入内存屏障指令。
<ul>
<li><strong>类型</strong>：
<ul>
<li><strong>写屏障（Store Barrier）</strong>：清空 Store Buffer，确保屏障前的写操作对其他 CPU 可见。</li>
<li><strong>读屏障（Load Barrier）</strong>：清空 Invalidation Queue，确保读到最新数据。</li>
<li><strong>全屏障（Full Barrier）</strong>：同时清空 Store Buffer 和 Invalidation Queue。</li>
</ul>
</li>
<li><strong>案例</strong>：
<ul>
<li><strong>Linux 内核（2005+）</strong>：<code>smp_wmb()</code>（写屏障）、<code>smp_rmb()</code>（读屏障）用于同步锁、RCU 等。</li>
<li><strong>Java volatile（2004）</strong>：JVM 通过插入 <code>lock addl $0x0, (%esp)</code> 实现屏障语义。</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="典型问题与案例分析"><strong>典型问题与案例分析</strong></h3>
<h4 id="1-可见性问题visibility"><strong>1. 可见性问题（Visibility）</strong></h4>
<ul>
<li>
<p><strong>示例</strong>：双线程循环检查 <code>flag</code> 变量：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-c" data-lang="c"><span style="display:flex;"><span><span style="color:#75715e">// 线程 A
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>data <span style="color:#f92672">=</span> <span style="color:#ae81ff">42</span>;          <span style="color:#75715e">// 写入 Store Buffer，未提交
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>flag <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;           <span style="color:#75715e">// Store Buffer 可能先于 data 提交
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// 线程 B
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">while</span> (flag <span style="color:#f92672">!=</span> <span style="color:#ae81ff">1</span>);  <span style="color:#75715e">// 看到 flag=1 但 data 可能仍是旧值
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#a6e22e">print</span>(data);
</span></span></code></pre></div></li>
<li>
<p><strong>解决</strong>：在 <code>data=42</code> 后插入写屏障，在 <code>while</code> 前插入读屏障。</p>
</li>
</ul>
<h4 id="2-乱序问题reordering"><strong>2. 乱序问题（Reordering）</strong></h4>
<ul>
<li>
<p><strong>示例</strong>：单核指令重排（Alpha 处理器著名案例）：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-asm" data-lang="asm"><span style="display:flex;"><span><span style="color:#a6e22e">STORE</span> <span style="color:#66d9ef">A</span><span style="color:#960050;background-color:#1e0010">=</span><span style="color:#ae81ff">1</span>           <span style="color:#75715e">; 存入 Store Buffer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#a6e22e">LOAD</span> <span style="color:#66d9ef">B</span><span style="color:#960050;background-color:#1e0010">=</span><span style="color:#ae81ff">0</span>            <span style="color:#75715e">; B 已在缓存中，立即读到 0
</span></span></span></code></pre></div><ul>
<li>其他 CPU 可能看到 <code>B=0</code> 先于 <code>A=1</code>。</li>
</ul>
</li>
<li>
<p><strong>解决</strong>：通过 <code>mfence</code> 指令禁止重排。</p>
</li>
</ul>
<hr>
<h3 id="演进总结"><strong>演进总结</strong></h3>
<p>单核缓存 → MESI 协议 → Store Buffer → Invalidation Queue → 内存屏障</p>
<ul>
<li><strong>性能优化</strong>：每一步都通过异步化（Asynchrony）提升吞吐量。</li>
<li><strong>复杂度转移</strong>：硬件优化导致软件需处理可见性和顺序问题，催生并发原语（锁、原子变量、RCU）。</li>
</ul>
<hr>
<h3 id="延伸方向"><strong>延伸方向</strong></h3>
<ol>
<li><strong>现代扩展</strong>：
<ul>
<li><strong>MOESI</strong>：AMD 提出的协议，允许缓存直接共享脏数据。</li>
<li><strong>Directory-Based 协议</strong>：NUMA 架构（如 EPYC）用目录集中管理一致性。</li>
</ul>
</li>
<li><strong>未来趋势</strong>：
<ul>
<li><strong>硅光互连</strong>：用光信号加速一致性消息传递（如 Intel 的集成光子学）。</li>
<li><strong>异构一致性</strong>：GPU/CPU 统一内存（如 NVIDIA Hopper 的 NVLink-C2C）。</li>
</ul>
</li>
</ol>
<p>希望这些补充能让知识结构更完整！如果需要进一步展开某个点，请随时告诉我。</p>

        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              
            </div>
          </div>

          



          
          
          <div style="height: 50px;"></div>
          
          <div class="post-comments">
            <div id="disqus_thread"></div>
<script>
  window.addEventListener("load", () => {
    (function() {
      
      var d = document,
        s = d.createElement("script");
      s.src = "https://joway.disqus.com/embed.js";
      s.setAttribute("data-timestamp", +new Date());
      (d.head || d.body).appendChild(s);
    })();
  });
</script>
<noscript
  >Please enable JavaScript to view the
  <a href="https://disqus.com/?ref_noscript"
    >comments powered by Disqus.</a
  ></noscript
>

          </div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  

<script>
  
  
    
    
  
</script>

  

</body>

</html>